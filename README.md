# Local Researcher

## Requirements
* Local model running [ollama](https://ollama.com) (or similar)
* SerpAPI key
* Jina API key

## Quick Start
1. Run ollama with ```ollama serve```.
2. Change the "default model" variable to the name of the LLM which is running locally.
3. Run the cells in order

Note: The report may take some time to generate (upwards of 30 minutes), depending on your hardware and chosen LLM.
